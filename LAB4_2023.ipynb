{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# learners\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# embeddings\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "- Create a dataframe by reading the file `eng.csv`. You can find the .csv file under \"files\" on Canvas. (We suggest you take a sample of the data, for example with 1,000, 10,000 or 20,000 instances, to save computing time.) \n",
    "\n",
    "- Use value_counts to see the counts for each value of the column, `emotion`. \n",
    "\n",
    "We will create models to predict emotions based on texts. Assign the `text` column to X and the `emotion` column to y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282313 entries, 0 to 282312\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   text      282313 non-null  object\n",
      " 1   emotion   282313 non-null  object\n",
      " 2   language  282313 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/eng.csv\")\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28231 entries, 75792 to 135931\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      28231 non-null  object\n",
      " 1   emotion   28231 non-null  object\n",
      " 2   language  28231 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 882.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with only 10,000 instances. Taking the top of the list\n",
    "#df = df.iloc[:10000, :]\n",
    "#df.info()\n",
    "\n",
    "# Taking 10000 instances with the .sample method\n",
    "#df = df.sample(10000)\n",
    "#df.info()\n",
    "\n",
    "# A random sample from the dataset. https://stackoverflow.com/questions/40986230/reduce-dataframe-size-in-pandas\n",
    "df = df.sample(frac=0.1) # Get 10% of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75792                                   him handle that....\n",
       "92255     [PHOTO] Wish u very very happy navraatri 0th d...\n",
       "17753              taking my mommy's first and middle names\n",
       "241103    [PHOTO] Preparing the birthday celebration ov ...\n",
       "66566     Every Time & Even Appreciated by The Music Sto...\n",
       "                                ...                        \n",
       "128152    called me when I was in hospital know you are ...\n",
       "112649    [PHOTO] Girls Night Tonight with my Beautiful ...\n",
       "130794    [PHOTO] Good evening my lovely friend s how ar...\n",
       "72122     [PHOTO] Totally buzzed to be part of DAMO SUZU...\n",
       "135931    do more nice and loving things for each other ...\n",
       "Name: text, Length: 28231, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning the text column to X and the emotions to y\n",
    "X = df.text\n",
    "y= df.emotion\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "- Perform a train test split and then fit_transform a `Countvectorizer` on X_train and transform X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splittinge the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18914x33472 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 356273 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the count vectorizer https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "vectorizer = CountVectorizer()\n",
    " \n",
    "#Fitting on the X_train data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "#Transforming both the training and test data\n",
    "X_train0 = vectorizer.transform(X_train)\n",
    "X_test0 = vectorizer.transform(X_test)\n",
    "\n",
    "# Summarizing the Encoded Texts. Copy pasted from the link\n",
    "#print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "#print(X_train.toarray())\n",
    "X_train0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting top N tokens\n",
    "Use the function below to plot the N most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def top_n_tokens(X, cv, N, plot=True):\n",
    "    sum_words = X.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    top_words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)[:N]\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar([w[0] for w in top_words_freq], [w[1] for w in top_words_freq])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.xlabel('Token')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return top_words_freq\n",
    "    \n",
    "top_n_tokens(\n",
    "    X= X_train0, \n",
    "    cv= vectorizer, \n",
    "    N=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "- Build one or more classifiers. \n",
    "- Report the accuracy score for vectorized train and test data.\n",
    "- Print a classification report for model performance on vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Fitting and predicting https://www.projectpro.io/recipes/generate-classification-report-and-confusion-matrix-in-python\n",
    "y_pred = knn.fit(X_train0, y_train).predict(X_test0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.20      0.31      0.24       574\n",
      "anticipation       0.46      0.64      0.54      3796\n",
      "        fear       0.14      0.12      0.13       123\n",
      "         joy       0.46      0.36      0.41      3590\n",
      "     sadness       0.49      0.11      0.18      1234\n",
      "\n",
      "    accuracy                           0.43      9317\n",
      "   macro avg       0.35      0.31      0.30      9317\n",
      "weighted avg       0.44      0.43      0.41      9317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "In the above model(s), we used unigrams (single words) only. This is the default for count_vectorizer. \n",
    "\n",
    "- Try with unigrams and bigrams, and also unigrams, bigrams and trigrams.  \n",
    "You do this by setting ngram_range for `CountVectorizer`. \n",
    "\n",
    "- Build a logistic regression model for each of these settings and report on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN BE BUILD IN MANY WAYS, BUT CONSIDER THE OUTPUT BELOW AS INSPIRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 5</h2>\n",
    "\n",
    "- Use dummy classifier with the default settings (most frequent class), and the uniform strategy (random guessing). \n",
    "\n",
    "- Select the `CountVectorizer` with the optimal `nram_range`. Use the vectorized version of the data from this model.\n",
    "- Print the train and test results for each dummy classifier, to determine some baselines for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.409\n",
      "Accuracy on test set: 0.407\n"
     ]
    }
   ],
   "source": [
    "# Making a dummy classifier model\n",
    "dummy_clf_M = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Fitting and predicting the model for most frequent\n",
    "y_pred_M = dummy_clf_M.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Printing scores\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dummy_clf_M.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dummy_clf_M.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.198\n",
      "Accuracy on test set: 0.201\n"
     ]
    }
   ],
   "source": [
    "# Making a dummy classifier model\n",
    "dummy_clf_U = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "# Fitting and predicting the model for uniform\n",
    "y_pred_U = dummy_clf_U.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Printing scores\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dummy_clf_U.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dummy_clf_U.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 221113 features, but KNeighborsClassifier is expecting 33472 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m X_test1 \u001b[39m=\u001b[39m vectorizer1\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Applying to the knn model made earlier and making a classification report\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_test1)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:219\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    217\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    220\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:745\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    743\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    744\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    747\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 221113 features, but KNeighborsClassifier is expecting 33472 features as input."
     ]
    }
   ],
   "source": [
    "# Trying n_gram ranges Using the count vectorizer https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "vectorizer1 = CountVectorizer(ngram_range=(1,2))\n",
    " \n",
    "#Fitting on the X_train data\n",
    "vectorizer1.fit(X_train)\n",
    "\n",
    "#Transforming both the training and test data\n",
    "X_train1 = vectorizer1.transform(X_train)\n",
    "X_test1 = vectorizer1.transform(X_test)\n",
    "\n",
    "# Applying to the knn model made earlier and making a classification report\n",
    "y_pred = knn.predict(X_test1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.18      0.32      0.23       565\n",
      "anticipation       0.48      0.58      0.52      3730\n",
      "        fear       0.09      0.10      0.10       114\n",
      "         joy       0.48      0.46      0.47      3683\n",
      "     sadness       0.57      0.11      0.19      1225\n",
      "\n",
      "    accuracy                           0.45      9317\n",
      "   macro avg       0.36      0.31      0.30      9317\n",
      "weighted avg       0.47      0.45      0.44      9317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying n_gram ranges Using the count vectorizer https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1,3))\n",
    " \n",
    "#Fitting on the X_train data\n",
    "vectorizer2.fit(X_train)\n",
    "\n",
    "#Transforming both the training and test data\n",
    "X_train2 = vectorizer2.transform(X_train)\n",
    "X_test2 = vectorizer2.transform(X_test)\n",
    "\n",
    "# Applying to the knn model made earlier and making a classification report\n",
    "y_pred = knn.predict(X_test2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.18      0.32      0.23       565\n",
      "anticipation       0.48      0.58      0.52      3730\n",
      "        fear       0.09      0.10      0.10       114\n",
      "         joy       0.48      0.46      0.47      3683\n",
      "     sadness       0.57      0.11      0.19      1225\n",
      "\n",
      "    accuracy                           0.45      9317\n",
      "   macro avg       0.36      0.31      0.30      9317\n",
      "weighted avg       0.47      0.45      0.44      9317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying n_gram ranges Using the count vectorizer https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1,4))\n",
    " \n",
    "#Fitting on the X_train data\n",
    "vectorizer3.fit(X_train)\n",
    "\n",
    "#Transforming both the training and test data\n",
    "X_train3 = vectorizer3.transform(X_train)\n",
    "X_test3 = vectorizer3.transform(X_test)\n",
    "\n",
    "# Applying to the knn model made earlier and making a classification report\n",
    "y_pred = knn.predict(X_test3)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different ngram_ranges have been tried out but the result does not seem to change? Not sure if i am doing things correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "- Use the `TfidfTransformer`, to create Term Frequency - Inverse Document Frequency (tfidf) scores instead of frequency scores. \n",
    "- You can apply the `TfidfTransformer` on the vectors created by `CountVectorizer`, using the fit_transform method just as is done with `CountVectorizer`. \n",
    "- Create a logistic regression model with the data produced by `TfidfTransformer`, and report the scores on train and test.\n",
    "\n",
    "- **TIP**: Instead of calculating frequencies with `CountVectorizer` and *then* calculating TF-IDF scores from said frequencies, you can import and call `TfidfVectorizer` directly, with the same syntax as you used for `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18914, 33109)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A lot of inspiration from here: https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Y_y69l6ZO3A\n",
    "# instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector_train=cv.fit_transform(X_train)\n",
    "\n",
    "# Seeing the result\n",
    "word_count_vector_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photo</th>\n",
       "      <td>1.628510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>1.769417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>1.772159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2.011627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2.024357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iamwill</th>\n",
       "      <td>10.154563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iamphosphene</th>\n",
       "      <td>10.154563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iamnru</th>\n",
       "      <td>10.154563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iammandaue</th>\n",
       "      <td>10.154563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>10.154563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33109 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idf_weights\n",
       "photo            1.628510\n",
       "with             1.769417\n",
       "person           1.772159\n",
       "and              2.011627\n",
       "to               2.024357\n",
       "...                   ...\n",
       "iamwill         10.154563\n",
       "iamphosphene    10.154563\n",
       "iamnru          10.154563\n",
       "iammandaue      10.154563\n",
       "            10.154563\n",
       "\n",
       "[33109 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the tfidf\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "\n",
    "# Fitting the model. Not sure whether to fit and or transform the test data?\n",
    "tfidf_transformer.fit(word_count_vector_train)\n",
    "#tfidf_transformer.transform(word_count_vector_test)\n",
    "\n",
    "# Preparing for showing the results\n",
    "X_train_df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "\n",
    "# sort ascending \n",
    "X_train_df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33109, 18914]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Instantiating logistic regression and fitting on the tfidf data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lr \u001b[39m=\u001b[39m LogisticRegression()\u001b[39m.\u001b[39;49mfit(X_train_df_idf, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Predictiting\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Printing scores\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy on training set: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(lr\u001b[39m.\u001b[39mscore(X_train, y_train)))\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1139\u001b[0m     X,\n\u001b[0;32m   1140\u001b[0m     y,\n\u001b[0;32m   1141\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1142\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1143\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1144\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1145\u001b[0m )\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33109, 18914]"
     ]
    }
   ],
   "source": [
    "# Not sure what actually goes wrong here\n",
    "# Instantiating logistic regression and fitting on the tfidf data\n",
    "lr = LogisticRegression().fit(X_train_df_idf, y_train)\n",
    "\n",
    "# Predictiting\n",
    "# Printing scores\n",
    "print(\"Accuracy on training set: {:.3f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.38      0.45       565\n",
      "anticipation       0.59      0.62      0.61      3730\n",
      "        fear       0.48      0.09      0.15       114\n",
      "         joy       0.56      0.60      0.58      3683\n",
      "     sadness       0.61      0.48      0.54      1225\n",
      "\n",
      "    accuracy                           0.58      9317\n",
      "   macro avg       0.55      0.44      0.46      9317\n",
      "weighted avg       0.58      0.58      0.57      9317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the TfidfVectorizer\n",
    "TVec = TfidfVectorizer()\n",
    "\n",
    "#Fitting the vector data on X_Train\n",
    "X_trainTVec = TVec.fit(X_train)\n",
    "\n",
    "\n",
    "#Transforming both the training and test data\n",
    "X_trainTV = vectorizer.transform(X_train)\n",
    "X_testTV = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic regression model with Fitting on the X_train data\n",
    "lrTV =LogisticRegression(random_state=42, max_iter=10000).fit(X_trainTV, y_train)\n",
    "\n",
    "# Applying to the knn model made earlier and making a classification report\n",
    "y_pred = lrTV.predict(X_testTV)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 7</h2>\n",
    "\n",
    "\n",
    "- Create a Scikit-Learn `Pipeline`, consisting of `CountVectorizer`, `TfidfTransformer`, and `LogisticRegression`. \n",
    "\n",
    "- Apply the pipeline to the training data, just as in the previous question, and report results on train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5920360631104433"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Pipeline https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "# Inspiration from here as well: https://medium.com/@soohyunniekimm/logistic-regression-with-columntransformer-pipeline-and-gridsearchcv-d2e3a781422f\n",
    "# Defining pipe\n",
    "pipe = Pipeline(steps=[\n",
    "    ('CountVectorizer',CountVectorizer()),\n",
    "    ('TfidfTransformer',TfidfTransformer()),\n",
    "    ('Model', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Fitting the pipeline with the data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Printing the score\n",
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.774\n",
      "Accuracy on test set: 0.592\n"
     ]
    }
   ],
   "source": [
    "# Printing scores\n",
    "print(\"Accuracy on training set: {:.3f}\".format(pipe.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 8</h2>\n",
    "\n",
    "- Use the above pipeline with GridSearchCV. \n",
    "\n",
    "**Hint** You can use the following choices for parameters: \n",
    "- for CountVectorizer, use ngram ranges of (1,1), (1,2), and (1,3). \n",
    "- For TfidfTransformer set the *use_idf* parameter to `True` or `False`. Print the best score and best parameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.854\n",
      "Accuracy on test set: 0.592\n",
      "Best params:  {'CountVectorizer__ngram_range': (1, 2), 'TfidfTransformer__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# Pipeline together with gridsearchCV: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "# Defining parameters for the param grid\n",
    "params = {\n",
    "    'CountVectorizer__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'TfidfTransformer__use_idf':[True,False]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=params,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "# Fitting the grid search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(search.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(search.score(X_test, y_test)))\n",
    "print(\"Best params: \", search.best_params_) # Printing the best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 9</h2>\n",
    "Use classification report with the best model resulting from grid_search in the previous two questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.76      0.20      0.32       565\n",
      "anticipation       0.59      0.69      0.64      3730\n",
      "        fear       0.00      0.00      0.00       114\n",
      "         joy       0.57      0.63      0.60      3683\n",
      "     sadness       0.68      0.41      0.51      1225\n",
      "\n",
      "    accuracy                           0.59      9317\n",
      "   macro avg       0.52      0.39      0.41      9317\n",
      "weighted avg       0.60      0.59      0.58      9317\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\lynma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Making a new pipeline, with the suggested optimal params\n",
    "pipe1 = Pipeline(steps=[\n",
    "    ('CountVectorizer',CountVectorizer(ngram_range=(1,2))),\n",
    "    ('TfidfTransformer',TfidfTransformer(use_idf=True)),\n",
    "    ('Model', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Fitting the pipeline with the data\n",
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with the optimal params\n",
    "y_pipePred = pipe1.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_test, y_pipePred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that anger gets high precision score, but so low recall score. On the other hand anticipation seems to have the highest F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Question 10\n",
    "Let's go back to question 1 and convert the problem to a binary classification problem. \n",
    "\n",
    "- Map (\"joy\", \"anticipation\") to \"positive\" and (\"anger\", \"fear\", \"sadness\") to \"negative\" (Use the snippet below)\n",
    "\n",
    "- Then copy/paste the experiments above here, and run them again with this new scope. \n",
    "- Report what your new baseline is and comment on the effect of changing the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"emotion\"] = df[\"emotion\"].replace(\n",
    "    {\n",
    "        \"joy\": \"positive\",\n",
    "        \"anticipation\": \"positive\",\n",
    "        \"anger\": \"negative\",\n",
    "        \"fear\": \"negative\",\n",
    "        \"sadness\": \"negative\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a new train test split\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "177413c0c7823e0fe5ce6e144f55cc71330c56be716ff616ac32165306d95ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
